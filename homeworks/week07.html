<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Probability: Interpretations, Axioms, and Measure Theory</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      margin: 0;
      padding: 0;
      background: #f7f7f7;
      color: #222;
    }
    .page {
      max-width: 800px;
      margin: 40px auto;
      padding: 24px;
      background: #fff;
      border-radius: 8px;
      box-shadow: 0 1px 3px rgba(0,0,0,.06);
    }
    h1, h2, h3 {
      font-weight: 600;
      margin-top: 1.5em;
      margin-bottom: 0.5em;
    }
    h1 {
      font-size: 1.8rem;
      margin-top: 0;
    }
    h2 {
      font-size: 1.35rem;
    }
    h3 {
      font-size: 1.1rem;
    }
    p {
      line-height: 1.6;
      margin: 0.6em 0;
    }
    code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.95em;
      background: #f0f0f0;
      padding: 0.05em 0.25em;
      border-radius: 4px;
    }
    .formula {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      display: block;
      padding: 4px 8px;
      margin: 8px 0;
      background: #fafafa;
      border-radius: 4px;
      overflow-x: auto;
      font-size: 0.95em;
    }
    ul {
      margin: 0.4em 0 0.4em 1.4em;
      padding: 0;
    }
  </style>
</head>
<body>
  <main class="page">
    <h1>Probability Theory: Interpretations, Axioms, and Measure Theory</h1>

    <p>
      Probability can be understood in several different ways (classical, frequentist, Bayesian, geometric, and more),
      and historically these led to conceptual tensions. The modern, axiomatic formulation of probability
      provides a common mathematical framework that accommodates all of these interpretations while keeping
      the core theory logically consistent. Measure theory then supplies the technical language that makes
      ‚Äúprobability spaces‚Äù precise and powerful.
    </p>

    <h2>1. Main Interpretations of Probability</h2>

    <h3>1.1 Classical (Laplacean) Interpretation</h3>
    <p>
      The classical interpretation defines probability in terms of symmetry and equally likely outcomes. For a finite
      sample space with equally likely elementary outcomes, the probability of an event <code>A</code> is
    </p>
    <p class="formula">
      P(A) = (number of favorable outcomes) / (number of possible outcomes).
    </p>
    <p>
      This works well for games of chance (dice, cards, coins) where symmetry is plausible, but it struggles with
      infinite sample spaces and situations where ‚Äúequally likely outcomes‚Äù are not clearly defined.
    </p>

    <h3>1.2 Frequentist Interpretation</h3>
    <p>
      The frequentist view identifies the probability of an event with its long-run relative frequency in repeated
      trials under identical conditions. If we repeat an experiment many times and observe that event <code>A</code>
      happens in a fraction of the trials close to <code>p</code>, we say that <code>P(A) = p</code>.
    </p>
    <p>
      This interpretation emphasizes observable frequencies and is natural for statistical inference. However, it has
      difficulty with single, non-repeatable events (e.g. ‚Äúthe probability there will be a major war in the next 50
      years‚Äù) and relies on an idealized notion of infinitely many repetitions.
    </p>

    <h3>1.3 Bayesian Interpretation</h3>
    <p>
      In the Bayesian interpretation, probability quantifies degrees of belief, given available information.
      Probabilities are fundamentally subjective, though they can be updated coherently using Bayes‚Äô theorem.
      If <code>H</code> is a hypothesis and <code>D</code> is data, Bayesian updating is given by
    </p>
    <p class="formula">
      P(H \mid D) = \dfrac{P(D \mid H)\,P(H)}{P(D)}.
    </p>
    <p>
      Here <code>P(H)</code> is the prior belief, <code>P(D \mid H)</code> is the likelihood, and
      <code>P(H \mid D)</code> is the posterior belief. Bayesians can handle single events naturally but face
      questions about how priors should be chosen and justified.
    </p>

    <h3>1.4 Geometric (or Uniform) Interpretation</h3>
    <p>
      The geometric interpretation arises when outcomes form a continuum and probability is proportional to
      geometric measure (length, area, volume). If a point is chosen ‚Äúat random‚Äù in a region <code>R</code>,
      and <code>A</code> is a subregion, we might define
    </p>
    <p class="formula">
      P(A) = \frac{\text{measure}(A)}{\text{measure}(R)}.
    </p>
    <p>
      This generalizes the classical idea of equally likely outcomes to continuous cases, but it depends on
      having an appropriate notion of ‚Äúuniform distribution‚Äù and a well-defined underlying measure.
    </p>

    <h3>1.5 How the Axiomatic Approach Reconciles These Views</h3>
    <p>
      The Kolmogorov axiomatic approach does not commit to any specific interpretation. Instead, it specifies
      abstract rules that any numerical assignment called ‚Äúprobability‚Äù must satisfy. In its basic (discrete) form,
      the axioms say that there is a function <code>P</code> on a collection of events such that:
    </p>
    <ul>
      <li><strong>(Non-negativity)</strong> For any event <code>A</code>, <code>P(A) ‚â• 0</code>.</li>
      <li><strong>(Normalization)</strong> <code>P(Œ©) = 1</code>, where <code>Œ©</code> is the sample space.</li>
      <li><strong>(Countable additivity)</strong> For pairwise disjoint events <code>A‚ÇÅ, A‚ÇÇ, ‚Ä¶</code>:
        <span class="formula">
          P\Bigl(\bigcup_{i=1}^{\infty} A_i\Bigr) = \sum_{i=1}^{\infty} P(A_i).
        </span>
      </li>
    </ul>
    <p>
      Classical, frequentist, Bayesian, and geometric probabilities can all be realized as specific models that satisfy
      these axioms:
    </p>
    <ul>
      <li>
        Classical probability corresponds to taking a finite (or countable) sample space with a uniform probability
        measure.
      </li>
      <li>
        Frequentist probabilities are understood as limits of empirical frequencies which, if they stabilize, define a
        probability measure satisfying the axioms.
      </li>
      <li>
        Bayesian probabilities treat <code>P</code> as a degree-of-belief function, but coherence requirements
        (e.g. avoiding sure-loss ‚ÄúDutch books‚Äù) force it to obey the same axioms.
      </li>
      <li>
        Geometric probabilities arise when <code>P</code> is defined using a normalized length/area/volume measure,
        which again satisfies the axioms.
      </li>
    </ul>
    <p>
      In this way, the axiomatic framework strips away interpretational disagreements and provides a neutral,
      consistent core: whatever ‚Äúprobability‚Äù means philosophically, it must behave mathematically like a probability
      measure.
    </p>

    <h2>2. Probability Theory as Measure Theory</h2>
    <p>
      Measure theory gives a precise mathematical language for talking about sizes of sets, integration, and limits.
      Probability theory fits into this framework by treating probabilities as measures on a space of outcomes.
    </p>

    <h3>2.1 Sigma-algebras of Events</h3>
    <p>
      Let <code>Œ©</code> be the set of all possible outcomes. A <strong>œÉ-algebra</strong> (sigma-algebra)
      <code>ùîΩ</code> on <code>Œ©</code> is a collection of subsets of <code>Œ©</code> (called
      <strong>events</strong>) such that:
    </p>
    <ul>
      <li><code>Œ© ‚àà ùîΩ</code>.</li>
      <li>If <code>A ‚àà ùîΩ</code>, then its complement <code>A·∂ú ‚àà ùîΩ</code>.</li>
      <li>If <code>A‚ÇÅ, A‚ÇÇ, ‚Ä¶ ‚àà ùîΩ</code>, then the union <code>‚ãÉ<sub>i=1</sub>^‚àû A·µ¢ ‚àà ùîΩ</code>.</li>
    </ul>
    <p>
      This structure is designed to be stable under the operations we routinely perform on events: taking complements,
      unions, and countable limits of such operations.
    </p>

    <h3>2.2 Probability Measures</h3>
    <p>
      A <strong>probability measure</strong> is a function
      <code>P : ùîΩ ‚Üí [0, 1]</code> on a œÉ-algebra <code>ùîΩ</code> satisfying the Kolmogorov axioms:
    </p>
    <ul>
      <li><code>P(Œ©) = 1</code>.</li>
      <li>If <code>A‚ÇÅ, A‚ÇÇ, ‚Ä¶</code> are pairwise disjoint events in <code>ùîΩ</code>, then
        <span class="formula">
          P\Bigl(\bigcup_{i=1}^{\infty} A_i\Bigr) = \sum_{i=1}^{\infty} P(A_i).
        </span>
      </li>
    </ul>
    <p>
      The triple <code>(Œ©, ùîΩ, P)</code> is called a <strong>probability space</strong>. From a measure-theoretic
      perspective, this is just a special case of a measure space where the total measure is 1.
    </p>

    <h3>2.3 Measurable Functions and Random Variables</h3>
    <p>
      Let <code>(Œ©, ùîΩ, P)</code> be a probability space and let <code>(‚Ñù, ùîÖ)</code> be the real line with its Borel
      œÉ-algebra (generated by open intervals). A function
    </p>
    <p class="formula">
      X : Œ© ‚Üí ‚Ñù
    </p>
    <p>
      is called a <strong>random variable</strong> if it is <strong>measurable</strong>, meaning that for every Borel
      set <code>B ‚àà ùîÖ</code>, the preimage <code>X‚Åª¬π(B) ‚àà ùîΩ</code>. Intuitively, this says that asking whether
      <code>X</code> falls in a set <code>B</code> corresponds to an event whose probability is defined.
    </p>
    <p>
      As soon as <code>X</code> is measurable, we can talk about the probability distribution of <code>X</code>.
      For any Borel set <code>B</code>, define
    </p>
    <p class="formula">
      P_X(B) = P(X ‚àà B) = P(X^{-1}(B)).
    </p>
    <p>
      This gives a probability measure on <code>(‚Ñù, ùîÖ)</code>, often described via distribution functions or densities.
      Expected values and variances are then integrals in the sense of Lebesgue:
    </p>
    <p class="formula">
      \mathbb{E}[X] = \int_{Œ©} X(\omega)\, dP(\omega).
    </p>
    <p>
      In summary, probability theory in its modern form is simply measure theory with the extra interpretation that the
      total measure is 1 and that measurable functions represent random variables.
    </p>

    <h2>3. Consequences of the Axioms: Subadditivity and Inclusion‚ÄìExclusion</h2>
    <p>
      Many familiar rules of probability follow from the axioms alone. Here we derive two of them: subadditivity and
      the inclusion‚Äìexclusion principle.
    </p>

    <h3>3.1 Subadditivity</h3>
    <p>
      The <strong>subadditivity</strong> property states that for any countable collection of events
      <code>A‚ÇÅ, A‚ÇÇ, ‚Ä¶</code>,
    </p>
    <p class="formula">
      P\Bigl(\bigcup_{i=1}^{\infty} A_i\Bigr) \le \sum_{i=1}^{\infty} P(A_i).
    </p>
    <p>
      This is weaker than countable additivity (which requires equality for disjoint events), but it holds in general.
      To prove it from the axioms, we construct a sequence of disjoint events from the <code>A·µ¢</code>.
    </p>

    <p>
      Define
    </p>
    <p class="formula">
      B_1 = A_1, \quad
      B_2 = A_2 \setminus A_1, \quad
      B_3 = A_3 \setminus (A_1 \cup A_2), \quad \dots
    </p>
    <p>
      In general,
    </p>
    <p class="formula">
      B_n = A_n \setminus \bigcup_{k=1}^{n-1} A_k.
    </p>
    <p>
      Then the <code>B·µ¢</code> are pairwise disjoint, and
    </p>
    <p class="formula">
      \bigcup_{i=1}^{\infty} A_i = \bigcup_{i=1}^{\infty} B_i.
    </p>
    <p>
      By construction, <code>B‚Çô ‚äÜ A‚Çô</code>, so monotonicity (which itself is derived from the axioms) gives
      <code>P(B‚Çô) ‚â§ P(A‚Çô)</code> for each <code>n</code>.
    </p>
    <p>
      Using countable additivity on the disjoint <code>B·µ¢</code>:
    </p>
    <p class="formula">
      P\Bigl(\bigcup_{i=1}^{\infty} A_i\Bigr)
      = P\Bigl(\bigcup_{i=1}^{\infty} B_i\Bigr)
      = \sum_{i=1}^{\infty} P(B_i)
      \le \sum_{i=1}^{\infty} P(A_i),
    </p>
    <p>
      which proves subadditivity.
    </p>

    <h3>3.2 Inclusion‚ÄìExclusion Principle</h3>
    <p>
      The <strong>inclusion‚Äìexclusion principle</strong> provides an exact formula for the probability of a union of
      finitely many events. For two events <code>A</code> and <code>B</code>, we have
    </p>
    <p class="formula">
      P(A \cup B) = P(A) + P(B) - P(A \cap B).
    </p>
    <p>
      This can be derived directly from the axioms. Observe that:
    </p>
    <p class="formula">
      A = (A \setminus B) \cup (A \cap B), \quad
      B = (B \setminus A) \cup (A \cap B),
    </p>
    <p>
      and all unions here are disjoint. Then
    </p>
    <p class="formula">
      A \cup B = (A \setminus B) \cup (B \setminus A) \cup (A \cap B),
    </p>
    <p>
      again a disjoint union. Using finite additivity (a special case of countable additivity), we get
    </p>
    <p class="formula">
      P(A) = P(A \setminus B) + P(A \cap B), \\
      P(B) = P(B \setminus A) + P(A \cap B).
    </p>
    <p>
      Adding these:
    </p>
    <p class="formula">
      P(A) + P(B) = P(A \setminus B) + P(B \setminus A) + 2P(A \cap B).
    </p>
    <p>
      On the other hand,
    </p>
    <p class="formula">
      P(A \cup B) = P(A \setminus B) + P(B \setminus A) + P(A \cap B).
    </p>
    <p>
      Subtracting the last equation from the previous one gives the desired identity:
    </p>
    <p class="formula">
      P(A \cup B) = P(A) + P(B) - P(A \cap B).
    </p>

    <h3>3.3 General Finite Inclusion‚ÄìExclusion</h3>
    <p>
      For finitely many events <code>A‚ÇÅ, ‚Ä¶, A‚Çô</code>, the inclusion‚Äìexclusion principle generalizes to
    </p>
    <p class="formula">
      P\Bigl(\bigcup_{i=1}^{n} A_i\Bigr)
      = \sum_{i} P(A_i)
      - \sum_{i<j} P(A_i \cap A_j)
      + \sum_{i<j<k} P(A_i \cap A_j \cap A_k)
      - \cdots
      + (-1)^{n-1} P(A_1 \cap \cdots \cap A_n).
    </p>
    <p>
      This formula can be proved rigorously by induction on <code>n</code>, using only the axioms of probability and
      basic set identities. Conceptually, it corrects for the over-counting that occurs when simply summing the
      individual probabilities of the <code>A·µ¢</code>.
    </p>

    <h2>4. Summary</h2>
    <p>
      The classical, frequentist, Bayesian, and geometric interpretations of probability emphasize different aspects of
      uncertainty: symmetry, long-run frequency, rational belief, and geometric measure. The axiomatic approach
      abstracts away from these interpretations and demands only that probabilities be numbers assigned to events in a
      œÉ-algebra so that the Kolmogorov axioms hold.
    </p>
    <p>
      Embedding this structure into measure theory via probability spaces and measurable functions yields a unified and
      highly flexible framework. Within it, fundamental properties such as subadditivity and the inclusion‚Äìexclusion
      principle emerge as straightforward consequences of the axioms, rather than ad hoc rules. Interpretations may
      differ philosophically, but mathematically they all live in the same axiomatic, measure-theoretic universe.
    </p>
  </main>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
